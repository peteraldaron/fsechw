\documentclass[12pt,letter]{article}
\usepackage{cite}
%\setCJKmainfont{SimSun}
%\documentclass[UTF8,nofonts]{ctexart}
\usepackage[english]{babel}
%\usepackage[utf8x]{inputenc}
\usepackage{graphicx}
\usepackage{parskip}
\usepackage{makeidx}
\usepackage{float}
\usepackage[shortlabels]{enumitem}
\usepackage{fullpage}
%\usepackage[margin=0.3in]{geometry}
\usepackage{amsmath}
\usepackage{multicol}
%\setlength{\parindent}{15pt}
\usepackage{amssymb}
\usepackage{verbatim}

\newcommand{\diff}{\frac{dy}{dt}}
\newcommand{\bs}{\begin{center}}
\newcommand{\es}{\end{center}}
\newcommand{\be}{\begin{enumerate}}
\newcommand{\ee}{\end{enumerate}}
\newcommand{\ars}{\left (\begin{array}{ccc}}
\newcommand{\are}{\end{array}\right )}
\newcommand{\ra} {\rightarrow}
\newcommand{\Ra} {\Rightarrow}
\newcommand{\la} {\leftarrow}

\begin{document}
  \title{F-Secure Homework Writeup}
  \author{Peter Zhang}
  \maketitle
  \section{Introduction}
  The assignment is to write a ``stream processor'' that analyses a stream of
  events from an application. I implemented the required features using
  Javascript on Node.js to answer the questions listed in the instructions. The
  following third-party Node.js packages are used:
  \be
  \item \texttt{bluebird} for promises.
  \item \texttt{lodash} for clean functional programming primitives.
  \item \texttt{line-reader} for reading the data file.
  \ee
  To install these dependencies, run:
  \begin{center}
      \texttt{
      npm install line-reader bluebird lodash
        }
  \end{center}

  All the code can be found in the \texttt{analysis.js} file in the repository:
  \begin{center}
  \texttt{https://github.com/peteraldaron/fsechw}.
  \end{center}

  \section{Structure}
  I adapted a pipeline-like design to for data processing, whose procedure is
  listed below:
  \be
  \item The program reads in the file line-by-line using line-reader.
  \item Using the built-in \texttt{JSON.parse} function, the JSON line is
      converted into a JS object.
  \item The source of the event, or the ``product name'', is identified. The
      program now stores data in product-specific fields.
  \item Using the ``\texttt{event\_id}'' field, duplicate events are identified,
      since every event can only have one unique event ID. This is implemented
      using a map (JS object).
  \item Afterwards, the types of events are being counted for the specific
      product.
  \item Then, the program accounts for the devices seen, as well as the first
      launch count from unique devices for the specific product. This stage also
      records the first and last seen time of the device for longest session
      computation.
  \item The program then moves onto counting the types of OS of client, as well
      as their geographical origins, which can be interesting for market
      penetration analysis.
  \ee

  Given the size of the data, it may be difficult to store the entirety of the
  raw data in memory. Therefore, I am only storing those data that are relevant
  to answering the questions posed, as well as other data of interest.

  \section{Findings}
  \subsection{Answer to Questions}
  \subsubsection{How many times has a particular product has been launched during this time
  period? How many first-time launches can you detect for this product?}
  \begin{tabular}{c| c c}
      Product & Launches & first-time launches by unique device\\
      \hline
      product-a & 11772 & 1118 \\
      product-b & 168360 & 35085 \\
      product-c & 16431 & 296 \\
      product-d & 223 & 38\\
  \end{tabular}
  \subsubsection{Can you detect duplicate events? How?}
  Yes. Through the event's event\_id field, which is unique for an individual
  event. The appearance of events are stored in a map (JS object) and any event
  that appears more than once is a duplicate.
  \subsubsection{Do you observe anything weird in timestamps?}
  A couple of things. Sometimes the event timestamp is smaller than
  event.time.(send or create)\_timestamp. This is likely due to the possibility
  that the client's time is not synchronized with the network. Another
  abnormality is that some events do not have the timestamp field. In this case,
  I use the event.time.send\_timestamp for time accouting instead.
  \subsubsection{Which device has longest `activity time' max(`first event â€“
  latest event')}
  Product-a's device with the longest activity time is e99b76bc26efd88aa31ab573ff3d8e72e3ee4b91, and the
  time between the first event and the last event is 25643690662 milliseconds,
  or 296.8 days.

  Product-b's device with the longest activity time is b3ebdd401e9aebc9c11475a010d864669cd63fc8, and the
  time between the first event and the last event is 24875526250 milliseconds,
  or 287.9 days.

  Product-c's device with the longest activity time is
  606df2e3df770fb16f1b10a2c23e88c2d75bd3e0, and the
  time between the first event and the last event is 25553708036 milliseconds,
  or 295.7 days.

  Product-d's device with the longest activity time is
  2eb0d958910d6351c403875022ab679c8feb6421, and the
  time between the first event and the last event is 7519999165 milliseconds,
  or 87.0 days.

  \subsubsection{How would you store the data so that further processing and/or
  analysis would be easy?}
  Since the data is already in JSON format, the easiest way to store the data is
  puting it into MongoDB, which stores the data in JSON format and also supports
  advanced querying, such as counting out-of-the-box.

  \subsubsection{If you should prepare a maintenance time for the processor,
  when would you do it in order to cause minimal impact to products?}
  To answer this question, we need to know when are the products least active,
  which can be acquired by making a histogram of the hours-of-day when all the events
  are being sent. The hour with the least amount of events is the time when the
  processor should be maintained.

  If the maintenance for the processor is separate for each product, then the
  best timings are:
  product-a: 2AM,\\
  product-b: 5AM,\\
  product-c: 3AM,\\
  product-d: 2AM.

  If the maintenance for the processor needs to be the same for all products,
  then the best timing is 5AM (15891 events).

  It is easy to plot the histogram bars using the final results output from the
  program. One will just need a plotting library.

  \subsubsection{What kind of statistics do you think are interesting? How could
  you visualize this?}
  I also did statistics of the country-of-origin of these events for separate
  products, as well as the operating system/platform count of events. These two
  measurements are particularly interesting because, depending on the kind of
  services the products provide, it might be interesting to know where the
  users are coming from and what kinds of devices they use, to better serve the
  customers. Both geographical location and platform (operating system)
  information is available in the JSON data.

  Geographical information can be visualized through plotting ``pins'' on a map,
  such as services provided by Google Maps. The operating system data, on the
  other hand, can be represented by pie charts.

  \subsection{Other Findings}
  A list of findings that I have noticed:
  \be
  \item product-a has predominately mobile users, while Android users contribute
      to the most to the number of actions.
  \item product-a has the most actions from Finland, but also from other parts
      of Europe, the US and Malaysia (MY).
  \item product-b has about a quarter of events from mobile users, while Android
      users contribute to the most to the amount of actions.
  \item product-b has the most actions from Finland (over 90\%), and the rest
      from other parts of Europe and the US.
  \item product-c has only mobile users, and Android
      users have the most number of actions.
  \item product-c has the most actions from Finland (over 99.9\%), and the rest
      is from the US.
  \item product-d has only iOS users.
  \item all users of product-d come from Finland.
  \ee

  \section{Future Work}

\end{document}
